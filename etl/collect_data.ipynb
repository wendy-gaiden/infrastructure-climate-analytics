{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1946cbdd-23bb-4922-957d-86a084407657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nYour First Data Collection Script\\nLet's start simple and build up!\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Your First Data Collection Script\n",
    "Let's start simple and build up!\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efc52b66-95a0-47af-9d4c-94dd21233450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wendylim/Desktop/infrastructure-climate-analytics/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6df054-44ec-4ee8-9e60-b9c270e9ba9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eb02586-b371-47f5-b4ed-2a7e95b15baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "452355e9-25b5-43d8-a945-a37c2a83215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Set up your paths\n",
    "# This ensures your script works from any directory\n",
    "# Option 1: Use current working directory\n",
    "BASE_DIR = Path.cwd()  # Gets current working directory\n",
    "\n",
    "# Option 2: If you want to specify exact path, uncomment and modify:\n",
    "# BASE_DIR = Path(\"/your/exact/path/to/infrastructure-climate-analytics\")\n",
    "\n",
    "# Option 3: Use relative path from where you run the script\n",
    "# BASE_DIR = Path(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bff2a09-08a1-4ff1-8242-497fc15bf91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data directories\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW_DATA_DIR = DATA_DIR / \"raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "704f2f7a-16d8-4411-83af-2e3d8b44ae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if they don't exist\n",
    "RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8df94654-ef56-4bc7-a11b-b8132e66c953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Working directory: /Users/wendylim/Desktop/infrastructure-climate-analytics\n",
      "üìÅ Data will be saved to: /Users/wendylim/Desktop/infrastructure-climate-analytics/data/raw\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"üìÅ Working directory: {BASE_DIR}\")\n",
    "print(f\"üìÅ Data will be saved to: {RAW_DATA_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46e077f8-3047-4b63-9dfa-f4265a9df9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_world_bank_indicator(indicator_code, indicator_name):\n",
    "    \"\"\"\n",
    "    Download a specific indicator from World Bank API\n",
    "    \n",
    "    Args:\n",
    "        indicator_code: World Bank indicator code (e.g., 'EN.ATM.CO2E.PC')\n",
    "        indicator_name: Friendly name for saving the file\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüìä Downloading {indicator_name}...\")\n",
    "    \n",
    "    # World Bank API endpoint\n",
    "    base_url = \"https://api.worldbank.org/v2/country/all/indicator\"\n",
    "    \n",
    "    # Build the full URL\n",
    "    url = f\"{base_url}/{indicator_code}\"\n",
    "    \n",
    "    # Parameters for the API call\n",
    "    params = {\n",
    "        'format': 'json',\n",
    "        'date': '2010:2023',  # Years we want\n",
    "        'per_page': '5000'    # Get all results in one page\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Make the API request\n",
    "        print(f\"   üîç Fetching from: {url}\")\n",
    "        response = requests.get(url, params=params)\n",
    "        \n",
    "        # Check if request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse JSON response\n",
    "            data = response.json()\n",
    "            \n",
    "            # World Bank returns data in second element of list\n",
    "            if len(data) > 1 and data[1]:\n",
    "                # Convert to DataFrame for easier handling\n",
    "                df = pd.DataFrame(data[1])\n",
    "                \n",
    "                # Save as CSV for easy viewing\n",
    "                output_file = RAW_DATA_DIR / f\"worldbank_{indicator_name}.csv\"\n",
    "                df.to_csv(output_file, index=False)\n",
    "                \n",
    "                print(f\"   ‚úÖ Saved {len(df)} rows to {output_file.name}\")\n",
    "                return df\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  No data found for {indicator_name}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"   ‚ùå Error: HTTP {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Failed to download {indicator_name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26b178b8-56d9-4053-8ca1-0a855d0ae4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_sample_infrastructure_data():\n",
    "    \"\"\"\n",
    "    Create sample infrastructure data\n",
    "    Since real infrastructure APIs often require keys, we'll create sample data\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nüèóÔ∏è Creating sample infrastructure resilience data...\")\n",
    "    \n",
    "    # Sample data representing infrastructure resilience scores\n",
    "    countries = [\n",
    "        'United States', 'China', 'Japan', 'Germany', 'India', \n",
    "        'United Kingdom', 'France', 'Italy', 'Brazil', 'Canada',\n",
    "        'South Korea', 'Spain', 'Australia', 'Mexico', 'Indonesia'\n",
    "    ]\n",
    "    \n",
    "    years = list(range(2010, 2024))\n",
    "    \n",
    "    # Create sample data\n",
    "    data = []\n",
    "    for country in countries:\n",
    "        for year in years:\n",
    "            # Simulate improving infrastructure scores over time\n",
    "            base_score = 50 + (countries.index(country) * 2)\n",
    "            year_improvement = (year - 2010) * 0.5\n",
    "            \n",
    "            data.append({\n",
    "                'country': country,\n",
    "                'year': year,\n",
    "                'infrastructure_score': base_score + year_improvement,\n",
    "                'transport_resilience': base_score + year_improvement + 5,\n",
    "                'energy_resilience': base_score + year_improvement - 5,\n",
    "                'water_resilience': base_score + year_improvement + 2,\n",
    "                'digital_resilience': base_score + year_improvement + 10\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = RAW_DATA_DIR / \"infrastructure_resilience_scores.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"   ‚úÖ Created sample data with {len(df)} rows\")\n",
    "    print(f\"   üìÑ Saved to {output_file.name}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd9bd849-3db3-4ec5-8392-2fd977201cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_catalog():\n",
    "    \"\"\"\n",
    "    Create a catalog of all downloaded data\n",
    "    This helps track what data you have and when it was downloaded\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nüìö Creating data catalog...\")\n",
    "    \n",
    "    catalog = []\n",
    "    \n",
    "    # Check all CSV files in raw data directory\n",
    "    for file in RAW_DATA_DIR.glob(\"*.csv\"):\n",
    "        # Get file info\n",
    "        file_stats = file.stat()\n",
    "        \n",
    "        # Read first few rows to get info\n",
    "        try:\n",
    "            df_sample = pd.read_csv(file, nrows=5)\n",
    "            total_rows = len(pd.read_csv(file))\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Could not read {file.name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        catalog.append({\n",
    "            'filename': file.name,\n",
    "            'rows': total_rows,\n",
    "            'columns': len(df_sample.columns),\n",
    "            'size_mb': round(file_stats.st_size / (1024 * 1024), 2),\n",
    "            'downloaded': datetime.fromtimestamp(file_stats.st_mtime).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        })\n",
    "    \n",
    "    if catalog:\n",
    "        # Create catalog DataFrame\n",
    "        catalog_df = pd.DataFrame(catalog)\n",
    "        \n",
    "        # Save catalog\n",
    "        catalog_file = DATA_DIR / \"data_catalog.csv\"\n",
    "        catalog_df.to_csv(catalog_file, index=False)\n",
    "        \n",
    "        print(f\"   ‚úÖ Catalog created with {len(catalog)} datasets\")\n",
    "        print(\"\\nüìä Data Catalog:\")\n",
    "        print(catalog_df.to_string())\n",
    "        \n",
    "        return catalog_df\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è No data files found to catalog\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad5bc3ca-e871-4479-8a40-864edf5c4368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_setup():\n",
    "    \"\"\"\n",
    "    Test if everything is set up correctly\n",
    "    \"\"\"\n",
    "    print(\"\\nüîß Testing Setup...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check Python version\n",
    "    import sys\n",
    "    print(f\"‚úÖ Python version: {sys.version}\")\n",
    "    \n",
    "    # Check if directories exist\n",
    "    if DATA_DIR.exists():\n",
    "        print(f\"‚úÖ Data directory exists: {DATA_DIR}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Data directory not found: {DATA_DIR}\")\n",
    "    \n",
    "    if RAW_DATA_DIR.exists():\n",
    "        print(f\"‚úÖ Raw data directory exists: {RAW_DATA_DIR}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Raw data directory not found: {RAW_DATA_DIR}\")\n",
    "    \n",
    "    # Check if we can write files\n",
    "    try:\n",
    "        test_file = RAW_DATA_DIR / \"test.txt\"\n",
    "        test_file.write_text(\"test\")\n",
    "        test_file.unlink()  # Delete test file\n",
    "        print(\"‚úÖ Can write to data directory\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Cannot write to data directory: {e}\")\n",
    "    \n",
    "    # Check internet connection\n",
    "    try:\n",
    "        response = requests.get(\"https://www.google.com\", timeout=5)\n",
    "        print(\"‚úÖ Internet connection working\")\n",
    "    except:\n",
    "        print(\"‚ùå No internet connection\")\n",
    "    \n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f40aad1-8606-4b25-a2cd-8e819f0cfbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üöÄ STARTING DATA COLLECTION PIPELINE\n",
      "============================================================\n",
      "\n",
      "üîß Testing Setup...\n",
      "============================================================\n",
      "‚úÖ Python version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 08:22:19) [Clang 14.0.6 ]\n",
      "‚úÖ Data directory exists: /Users/wendylim/Desktop/infrastructure-climate-analytics/data\n",
      "‚úÖ Raw data directory exists: /Users/wendylim/Desktop/infrastructure-climate-analytics/data/raw\n",
      "‚úÖ Can write to data directory\n",
      "‚úÖ Internet connection working\n",
      "============================================================\n",
      "\n",
      "üìä Downloading co2_emissions_per_capita...\n",
      "   üîç Fetching from: https://api.worldbank.org/v2/country/all/indicator/EN.GHG.CO2.PC.CE.AR5\n",
      "   ‚úÖ Saved 3724 rows to worldbank_co2_emissions_per_capita.csv\n",
      "\n",
      "üìä Downloading gdp_per_capita...\n",
      "   üîç Fetching from: https://api.worldbank.org/v2/country/all/indicator/NY.GDP.PCAP.CD\n",
      "   ‚úÖ Saved 3724 rows to worldbank_gdp_per_capita.csv\n",
      "\n",
      "üìä Downloading population_total...\n",
      "   üîç Fetching from: https://api.worldbank.org/v2/country/all/indicator/SP.POP.TOTL\n",
      "   ‚úÖ Saved 3724 rows to worldbank_population_total.csv\n",
      "\n",
      "üìä Downloading renewable_energy_consumption...\n",
      "   üîç Fetching from: https://api.worldbank.org/v2/country/all/indicator/EG.FEC.RNEW.ZS\n",
      "   ‚úÖ Saved 3724 rows to worldbank_renewable_energy_consumption.csv\n",
      "\n",
      "üèóÔ∏è Creating sample infrastructure resilience data...\n",
      "   ‚úÖ Created sample data with 210 rows\n",
      "   üìÑ Saved to infrastructure_resilience_scores.csv\n",
      "\n",
      "üìö Creating data catalog...\n",
      "   ‚úÖ Catalog created with 5 datasets\n",
      "\n",
      "üìä Data Catalog:\n",
      "                                     filename  rows  columns  size_mb           downloaded\n",
      "0  worldbank_renewable_energy_consumption.csv  3724        8     0.59  2025-08-30 16:16:49\n",
      "1      worldbank_co2_emissions_per_capita.csv  3724        8     0.67  2025-08-30 16:16:44\n",
      "2                worldbank_gdp_per_capita.csv  3724        8     0.49  2025-08-30 16:16:45\n",
      "3        infrastructure_resilience_scores.csv   210        7     0.01  2025-08-30 16:16:50\n",
      "4              worldbank_population_total.csv  3724        8     0.42  2025-08-30 16:16:47\n",
      "\n",
      "============================================================\n",
      "‚úÖ DATA COLLECTION COMPLETE!\n",
      "============================================================\n",
      "\n",
      "üìÅ All data saved to: /Users/wendylim/Desktop/infrastructure-climate-analytics/data/raw\n",
      "üìä Total datasets collected: 5\n",
      "üíæ Total size: 2.18 MB\n",
      "\n",
      "üìÑ Collection report saved to: collection_report.json\n",
      "\n",
      "üéâ Script execution completed!\n",
      "üìö Next steps:\n",
      "   1. Check the data/raw folder for your downloaded files\n",
      "   2. Review any error messages above\n",
      "   3. Open Jupyter notebook to explore the data\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run all data collection\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"üöÄ STARTING DATA COLLECTION PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # First, test the setup\n",
    "    test_setup()\n",
    "    \n",
    "    # Define World Bank indicators we want\n",
    "    # These are relevant to infrastructure and climate\n",
    "    indicators = {\n",
    "        'EN.GHG.CO2.PC.CE.AR5': 'co2_emissions_per_capita',\n",
    "        'NY.GDP.PCAP.CD': 'gdp_per_capita',\n",
    "        'SP.POP.TOTL': 'population_total',\n",
    "        'EG.FEC.RNEW.ZS': 'renewable_energy_consumption',\n",
    "        # Note: Some indicators might not have data\n",
    "        # 'IS.ROD.PAVE.ZS': 'roads_paved_percentage',\n",
    "        # 'IS.RRS.TOTL.KM': 'railway_lines_total_km'\n",
    "    }\n",
    "    \n",
    "    # Download each indicator\n",
    "    downloaded_data = {}\n",
    "    for code, name in indicators.items():\n",
    "        df = download_world_bank_indicator(code, name)\n",
    "        if df is not None:\n",
    "            downloaded_data[name] = df\n",
    "        \n",
    "        # Be nice to the API - wait between requests\n",
    "        time.sleep(1)\n",
    "    \n",
    "    # Create sample infrastructure data\n",
    "    infra_data = download_sample_infrastructure_data()\n",
    "    \n",
    "    # Create data catalog\n",
    "    catalog = create_data_catalog()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"‚úÖ DATA COLLECTION COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not catalog.empty:\n",
    "        print(f\"\\nüìÅ All data saved to: {RAW_DATA_DIR}\")\n",
    "        print(f\"üìä Total datasets collected: {len(catalog)}\")\n",
    "        print(f\"üíæ Total size: {catalog['size_mb'].sum():.2f} MB\")\n",
    "        \n",
    "        # Save a summary report\n",
    "        report = {\n",
    "            'run_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "            'datasets_collected': len(catalog),\n",
    "            'total_size_mb': float(catalog['size_mb'].sum()),\n",
    "            'data_directory': str(RAW_DATA_DIR)\n",
    "        }\n",
    "        \n",
    "        report_file = DATA_DIR / \"collection_report.json\"\n",
    "        with open(report_file, 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nüìÑ Collection report saved to: {report_file.name}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No data was collected. Please check the errors above.\")\n",
    "    \n",
    "    return downloaded_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the data collection\n",
    "    data = main()\n",
    "    \n",
    "    print(\"\\nüéâ Script execution completed!\")\n",
    "    print(\"üìö Next steps:\")\n",
    "    print(\"   1. Check the data/raw folder for your downloaded files\")\n",
    "    print(\"   2. Review any error messages above\")\n",
    "    print(\"   3. Open Jupyter notebook to explore the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b3d3b-4a62-4a44-8dce-a1388ebb8fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
